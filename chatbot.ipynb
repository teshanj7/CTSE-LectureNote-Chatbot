{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D4VonqP9Eq_"
      },
      "source": [
        "# CTSE - Assignment 2 - Lecture notes chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCeidfLP9Se6"
      },
      "source": [
        "# Install all the dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install google-generativeai langchain langchain_community pypdf nltk sentence-transformers faiss-cpu python-dotenv python-pptx unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1nWdjUg-csX"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import nltk\n",
        "import google.generativeai as genai\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from IPython.display import Markdown, display\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import UnstructuredPowerPointLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Qizbn6-nMz"
      },
      "source": [
        "# Load environment variables from .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iop9dwYa-7ux"
      },
      "source": [
        "# Download NLTK resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIW2yhxl_Gwz"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szqKoatW_JCp"
      },
      "source": [
        "# Get API key from environment variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WtbtR6p_Lz9"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"API key not found. Please make sure your .env file contains the GEMINI_API_KEY.\")\n",
        "    #GEMINI_API_KEY = \"API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Cm6vIy_OSM"
      },
      "source": [
        "# Set up Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0sM8vkmAvvc"
      },
      "outputs": [],
      "source": [
        "def setup_gemini(api_key):\n",
        "    \"\"\"Configure and initialize the Gemini model.\"\"\"\n",
        "    genai.configure(api_key=api_key)\n",
        "    \n",
        "    generation_config = {\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_output_tokens\": 1024,\n",
        "    }\n",
        "    \n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro\",\n",
        "        generation_config=generation_config\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebI7nbqeA0UL"
      },
      "source": [
        "# Load documents from datasets folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELfTnYORA67B"
      },
      "outputs": [],
      "source": [
        "def load_documents():\n",
        "    \"\"\"Load CTSE lecture notes from the datasets folder.\"\"\"\n",
        "    documents = []\n",
        "    data_folder = 'datasets'\n",
        "    \n",
        "    # Check if folder exists\n",
        "    if not os.path.exists(data_folder):\n",
        "        print(f\"Warning: The '{data_folder}' folder does not exist.\")\n",
        "        return documents\n",
        "    \n",
        "    # Load PDF files\n",
        "    pdf_files = glob.glob(os.path.join(data_folder, '**', '*.pdf'), recursive=True)\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            loader = PyPDFLoader(pdf_file)\n",
        "            documents.extend(loader.load())\n",
        "            print(f\"Loaded PDF: {pdf_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading PDF {pdf_file}: {e}\")\n",
        "    \n",
        "    # Load PowerPoint files (PPT and PPTX)\n",
        "    # PPT files (older format)\n",
        "    ppt_files = glob.glob(os.path.join(data_folder, '**', '*.ppt'), recursive=True)\n",
        "    # PPTX files (newer format)\n",
        "    pptx_files = glob.glob(os.path.join(data_folder, '**', '*.pptx'), recursive=True)\n",
        "    \n",
        "    # Combine both lists\n",
        "    all_ppt_files = ppt_files + pptx_files\n",
        "    \n",
        "    for ppt_file in all_ppt_files:\n",
        "        try:\n",
        "            loader = UnstructuredPowerPointLoader(ppt_file)\n",
        "            documents.extend(loader.load())\n",
        "            print(f\"Loaded PowerPoint: {ppt_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading PowerPoint {ppt_file}: {e}\")\n",
        "    \n",
        "    return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHEErWI_CezW"
      },
      "source": [
        "# Process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv3Rv2XPClx1"
      },
      "outputs": [],
      "source": [
        "def create_vector_store(documents):\n",
        "    \"\"\"Create a searchable vector database from documents.\"\"\"\n",
        "    if not documents:\n",
        "        print(\"No documents to process.\")\n",
        "        return None\n",
        "    \n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split into {len(chunks)} chunks.\")\n",
        "    \n",
        "    # Create embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "    \n",
        "    # Create vector store\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    return vector_store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW958AiMCuEH"
      },
      "source": [
        "# Generate response using RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp6o4sjOCwnf"
      },
      "outputs": [],
      "source": [
        "def answer_question(question, vector_store, model):\n",
        "    \"\"\"Generate an answer using Retrieval-Augmented Generation.\"\"\"\n",
        "    # Retrieve relevant documents\n",
        "    docs = vector_store.similarity_search(question, k=5)\n",
        "    \n",
        "    # Create context from retrieved documents\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    \n",
        "    # Generate prompt for Gemini\n",
        "    prompt = f\"\"\"\n",
        "    You are a teaching assistant helping students with Computer Science and Technology for Software Engineering (CTSE) concepts.\n",
        "    Answer the following question based ONLY on the provided context from CTSE lecture notes.\n",
        "    If you cannot find the answer in the context, state that you don't have that information.\n",
        "    \n",
        "    Context:\n",
        "    {context}\n",
        "    \n",
        "    Question: {question}\n",
        "    \n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    \n",
        "    # Generate response\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdraJWatDAgb"
      },
      "source": [
        "# Main execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyqoGUBsDHzl"
      },
      "outputs": [],
      "source": [
        "print(\"=== CTSE Lecture Notes Chatbot ===\")\n",
        "\n",
        "# Setup model\n",
        "print(\"Setting up the Gemini model...\")\n",
        "model = setup_gemini(GEMINI_API_KEY)\n",
        "\n",
        "# Load documents\n",
        "print(\"\\nLoading documents from the 'datasets' folder...\")\n",
        "documents = load_documents()\n",
        "\n",
        "if not documents:\n",
        "    print(\"No documents found. Please make sure your CTSE lecture notes are in the 'datasets' folder.\")\n",
        "else:\n",
        "    # Process documents\n",
        "    print(\"\\nProcessing documents and creating vector store...\")\n",
        "    vector_store = create_vector_store(documents)\n",
        "    \n",
        "    if vector_store:\n",
        "        print(\"\\nChatbot ready! You can now ask questions about your CTSE lecture notes.\")\n",
        "        print(\"Type 'exit' to end the conversation.\")\n",
        "        \n",
        "        # Chat loop\n",
        "        while True:\n",
        "            question = input(\"\\nYour question: \")\n",
        "            \n",
        "            if question.lower() in ['exit', 'quit', 'bye']:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "            \n",
        "            # Answer the question\n",
        "            print(\"Generating answer...\")\n",
        "            answer = answer_question(question, vector_store, model)\n",
        "            display(Markdown(f\"**Answer:**\\n{answer}\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
