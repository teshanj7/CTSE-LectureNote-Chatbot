{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D4VonqP9Eq_"
      },
      "source": [
        "# CTSE - Assignment 2 - Lecture notes chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCeidfLP9Se6"
      },
      "source": [
        "# Install all the dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlPV7AlL9hcT",
        "outputId": "ca37300c-b24e-4da3-8a1d-a22a5dbad8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "     ------------------------------------ 155.4/155.4 kB 319.8 kB/s eta 0:00:00\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
            "     ---------------------------------------- 1.0/1.0 MB 1.5 MB/s eta 0:00:00\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "     ---------------------------------------- 2.5/2.5 MB 3.2 MB/s eta 0:00:00\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "     -------------------------------------- 303.4/303.4 kB 3.1 MB/s eta 0:00:00\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 2.8 MB/s eta 0:00:00\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "     -------------------------------------- 345.7/345.7 kB 3.6 MB/s eta 0:00:00\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-win_amd64.whl (15.0 MB)\n",
            "     ---------------------------------------- 15.0/15.0 MB 3.2 MB/s eta 0:00:00\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "     -------------------------------------- 472.8/472.8 kB 4.2 MB/s eta 0:00:00\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "     ---------------------------------------- 1.8/1.8 MB 2.7 MB/s eta 0:00:00\n",
            "Collecting google-ai-generativelanguage==0.6.15\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "     ---------------------------------------- 1.3/1.3 MB 2.2 MB/s eta 0:00:00\n",
            "Collecting google-api-core\n",
            "  Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
            "     -------------------------------------- 160.1/160.1 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
            "     ---------------------------------------- 13.3/13.3 MB 3.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.23.2)\n",
            "Requirement already satisfied: protobuf in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.24.3)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "     -------------------------------------- 443.9/443.9 kB 3.9 MB/s eta 0:00:00\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.8.0)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
            "  Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "     ---------------------------------------- 50.2/50.2 kB 2.7 MB/s eta 0:00:00\n",
            "Collecting langchain-core<1.0.0,>=0.3.58\n",
            "  Downloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
            "     -------------------------------------- 437.7/437.7 kB 2.5 MB/s eta 0:00:00\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17\n",
            "  Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
            "     -------------------------------------- 360.3/360.3 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting SQLAlchemy<3,>=1.4\n",
            "  Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "     ---------------------------------------- 2.1/2.1 MB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
            "     -------------------------------------- 443.7/443.7 kB 2.3 MB/s eta 0:00:00\n",
            "Collecting tenacity!=8.4.0,<10,>=8.1.0\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting numpy>=1.26.2\n",
            "  Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "     ---------------------------------------- 12.9/12.9 MB 2.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: click in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
            "     -------------------------------------- 274.1/274.1 kB 2.8 MB/s eta 0:00:00\n",
            "Collecting transformers<5.0.0,>=4.41.0\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "     ---------------------------------------- 10.4/10.4 MB 3.4 MB/s eta 0:00:00\n",
            "Collecting torch>=1.11.0\n",
            "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
            "     -------------------------------------- 212.5/212.5 MB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
            "Collecting huggingface-hub>=0.20.0\n",
            "  Downloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "     -------------------------------------- 484.3/484.3 kB 2.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: Pillow in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (23.1)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "     -------------------------------------- 169.4/169.4 kB 1.7 MB/s eta 0:00:00\n",
            "Collecting lxml>=3.1.0\n",
            "  Downloading lxml-5.4.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
            "     ---------------------------------------- 3.8/3.8 MB 3.0 MB/s eta 0:00:00\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "     ---------------------------------------- 45.8/45.8 kB ? eta 0:00:00\n",
            "Collecting chardet\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "     -------------------------------------- 199.4/199.4 kB 2.0 MB/s eta 0:00:00\n",
            "Collecting filetype\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "     -------------------------------------- 590.6/590.6 kB 2.9 MB/s eta 0:00:00\n",
            "Collecting python-iso639\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "     -------------------------------------- 167.6/167.6 kB 2.5 MB/s eta 0:00:00\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "     -------------------------------------- 981.5/981.5 kB 3.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
            "     ---------------------------------------- 1.6/1.6 MB 4.2 MB/s eta 0:00:00\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting unstructured-client\n",
            "  Downloading unstructured_client-0.34.0-py3-none-any.whl (189 kB)\n",
            "     -------------------------------------- 189.4/189.4 kB 2.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wrapt in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (7.0.0)\n",
            "Collecting python-oxmsg\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Collecting html5lib\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "     -------------------------------------- 112.2/112.2 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
            "     -------------------------------------- 120.9/120.9 kB 1.4 MB/s eta 0:00:00\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
            "     ---------------------------------------- 45.2/45.2 kB 1.1 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
            "     ---------------------------------------- 93.4/93.4 kB 1.8 MB/s eta 0:00:00\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "     ---------------------------------------- 50.9/50.9 kB 2.5 MB/s eta 0:00:00\n",
            "Collecting typing-inspect<1,>=0.4.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "     -------------------------------------- 194.4/194.4 kB 2.0 MB/s eta 0:00:00\n",
            "Collecting jsonpatch<2.0,>=1.33\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14\n",
            "  Downloading orjson-3.10.18-cp311-cp311-win_amd64.whl (134 kB)\n",
            "     -------------------------------------- 134.6/134.6 kB 2.7 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "     ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
            "Collecting zstandard<0.24.0,>=0.23.0\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
            "     -------------------------------------- 495.4/495.4 kB 2.8 MB/s eta 0:00:00\n",
            "Collecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.33.2\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "     ---------------------------------------- 2.0/2.0 MB 3.2 MB/s eta 0:00:00\n",
            "Collecting typing-inspection>=0.4.0\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Collecting greenlet>=1\n",
            "  Downloading greenlet-3.2.2-cp311-cp311-win_amd64.whl (295 kB)\n",
            "     -------------------------------------- 295.4/295.4 kB 2.6 MB/s eta 0:00:00\n",
            "Collecting sympy>=1.13.3\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "     ---------------------------------------- 6.3/6.3 MB 3.1 MB/s eta 0:00:00\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 1.7/1.7 MB 2.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jinja2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Collecting tokenizers<0.22,>=0.21\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "     ---------------------------------------- 2.4/2.4 MB 2.3 MB/s eta 0:00:00\n",
            "Collecting safetensors>=0.4.3\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "     -------------------------------------- 308.9/308.9 kB 3.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "     -------------------------------------- 294.5/294.5 kB 2.3 MB/s eta 0:00:00\n",
            "Collecting httplib2<1.0.0,>=0.19.0\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "     ---------------------------------------- 96.9/96.9 kB 2.8 MB/s eta 0:00:00\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.9 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
            "Collecting olefile\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "     -------------------------------------- 114.6/114.6 kB 2.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Collecting numpy>=1.26.2\n",
            "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
            "     ---------------------------------------- 15.8/15.8 MB 3.6 MB/s eta 0:00:00\n",
            "Collecting aiofiles>=24.1.0\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting cryptography>=3.1\n",
            "  Downloading cryptography-44.0.3-cp39-abi3-win_amd64.whl (3.2 MB)\n",
            "     ---------------------------------------- 3.2/3.2 MB 3.3 MB/s eta 0:00:00\n",
            "Collecting eval-type-backport>=0.2.0\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai) (1.59.0)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
            "  Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.0)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "     -------------------------------------- 536.2/536.2 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: pycparser in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "     -------------------------------------- 434.5/434.5 kB 2.7 MB/s eta 0:00:00\n",
            "Collecting grpcio<2.0dev,>=1.33.2\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
            "     ---------------------------------------- 4.3/4.3 MB 3.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\teshan jayakody\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py): started\n",
            "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=ae208fabe4fb6bc01c957792e1788d23ee161c7238e9e5fd5a38e66ddef2cb13\n",
            "  Stored in directory: c:\\users\\teshan jayakody\\appdata\\local\\pip\\cache\\wheels\\82\\db\\43\\cb54039c7e77322827cbefaa8caccdfa43daad323801c138f4\n",
            "Successfully built langdetect\n",
            "Installing collected packages: mpmath, filetype, zstandard, XlsxWriter, uritemplate, typing-extensions, tqdm, tenacity, sympy, safetensors, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, protobuf, propcache, packaging, orjson, olefile, numpy, networkx, mypy-extensions, multidict, lxml, langdetect, jsonpatch, httpx-sse, httplib2, html5lib, grpcio, greenlet, fsspec, frozenlist, filelock, eval-type-backport, emoji, chardet, backoff, annotated-types, aiohappyeyeballs, aiofiles, yarl, typing-inspection, typing-inspect, torch, SQLAlchemy, requests-toolbelt, python-pptx, python-oxmsg, pydantic-core, proto-plus, nltk, marshmallow, huggingface-hub, googleapis-common-protos, faiss-cpu, cryptography, aiosignal, tokenizers, pydantic, grpcio-status, google-auth-httplib2, google-api-core, dataclasses-json, aiohttp, unstructured-client, transformers, pydantic-settings, langsmith, google-api-python-client, unstructured, sentence-transformers, langchain-core, google-ai-generativelanguage, langchain-text-splitters, google-generativeai, langchain, langchain_community\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.24.3\n",
            "    Uninstalling protobuf-4.24.3:\n",
            "      Successfully uninstalled protobuf-4.24.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.59.0\n",
            "    Uninstalling grpcio-1.59.0:\n",
            "      Successfully uninstalled grpcio-1.59.0\n",
            "Successfully installed SQLAlchemy-2.0.40 XlsxWriter-3.2.3 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 backoff-2.2.1 chardet-5.2.0 cryptography-44.0.3 dataclasses-json-0.6.7 emoji-2.14.1 eval-type-backport-0.2.2 faiss-cpu-1.11.0 filelock-3.18.0 filetype-1.2.0 frozenlist-1.6.0 fsspec-2025.3.2 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.169.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 greenlet-3.2.2 grpcio-1.71.0 grpcio-status-1.71.0 html5lib-1.1 httplib2-0.22.0 httpx-sse-0.4.0 huggingface-hub-0.31.1 jsonpatch-1.33 langchain-0.3.25 langchain-core-0.3.59 langchain-text-splitters-0.3.8 langchain_community-0.3.23 langdetect-1.0.9 langsmith-0.3.42 lxml-5.4.0 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.4.3 mypy-extensions-1.1.0 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 olefile-0.47 orjson-3.10.18 packaging-24.2 propcache-0.3.1 proto-plus-1.26.1 protobuf-5.29.4 pydantic-2.11.4 pydantic-core-2.33.2 pydantic-settings-2.9.1 pypdf-5.5.0 python-dotenv-1.1.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 python-pptx-1.0.2 rapidfuzz-3.13.0 regex-2024.11.6 requests-toolbelt-1.0.0 safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 tenacity-9.1.2 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 typing-inspect-0.9.0 typing-inspection-0.4.0 unstructured-0.17.2 unstructured-client-0.34.0 uritemplate-4.1.1 yarl-1.20.0 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "%pip install google-generativeai langchain langchain_community pypdf nltk sentence-transformers faiss-cpu python-dotenv python-pptx unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1nWdjUg-csX"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa4Goy8l-f2Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import nltk\n",
        "import google.generativeai as genai\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from IPython.display import Markdown, display\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import UnstructuredPowerPointLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Qizbn6-nMz"
      },
      "source": [
        "# Load environment variables from .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX95li-y-4xV",
        "outputId": "5fd8d67f-4267-4835-a313-16706237f2ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iop9dwYa-7ux"
      },
      "source": [
        "# Download NLTK resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIW2yhxl_Gwz"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szqKoatW_JCp"
      },
      "source": [
        "# Get API key from environment variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WtbtR6p_Lz9"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"API key not found. Please make sure your .env file contains the GEMINI_API_KEY.\")\n",
        "    #GEMINI_API_KEY = \"API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Cm6vIy_OSM"
      },
      "source": [
        "# Set up Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0sM8vkmAvvc"
      },
      "outputs": [],
      "source": [
        "def setup_gemini(api_key):\n",
        "    \"\"\"Configure and initialize the Gemini model.\"\"\"\n",
        "    genai.configure(api_key=api_key)\n",
        "    \n",
        "    generation_config = {\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_output_tokens\": 1024,\n",
        "    }\n",
        "    \n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro\",\n",
        "        generation_config=generation_config\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebI7nbqeA0UL"
      },
      "source": [
        "# Load documents from datasets folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELfTnYORA67B"
      },
      "outputs": [],
      "source": [
        "def load_documents():\n",
        "    \"\"\"Load CTSE lecture notes from the datasets folder.\"\"\"\n",
        "    documents = []\n",
        "    data_folder = 'datasets'\n",
        "    \n",
        "    # Check if folder exists\n",
        "    if not os.path.exists(data_folder):\n",
        "        print(f\"Warning: The '{data_folder}' folder does not exist.\")\n",
        "        return documents\n",
        "    \n",
        "    # Load PDF files\n",
        "    pdf_files = glob.glob(os.path.join(data_folder, '**', '*.pdf'), recursive=True)\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            loader = PyPDFLoader(pdf_file)\n",
        "            documents.extend(loader.load())\n",
        "            print(f\"Loaded PDF: {pdf_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading PDF {pdf_file}: {e}\")\n",
        "    \n",
        "    # Load PowerPoint files (PPT and PPTX)\n",
        "    # PPT files (older format)\n",
        "    ppt_files = glob.glob(os.path.join(data_folder, '**', '*.ppt'), recursive=True)\n",
        "    # PPTX files (newer format)\n",
        "    pptx_files = glob.glob(os.path.join(data_folder, '**', '*.pptx'), recursive=True)\n",
        "    \n",
        "    # Combine both lists\n",
        "    all_ppt_files = ppt_files + pptx_files\n",
        "    \n",
        "    for ppt_file in all_ppt_files:\n",
        "        try:\n",
        "            loader = UnstructuredPowerPointLoader(ppt_file)\n",
        "            documents.extend(loader.load())\n",
        "            print(f\"Loaded PowerPoint: {ppt_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading PowerPoint {ppt_file}: {e}\")\n",
        "    \n",
        "    return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHEErWI_CezW"
      },
      "source": [
        "# Process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv3Rv2XPClx1"
      },
      "outputs": [],
      "source": [
        "def create_vector_store(documents):\n",
        "    \"\"\"Create a searchable vector database from documents.\"\"\"\n",
        "    if not documents:\n",
        "        print(\"No documents to process.\")\n",
        "        return None\n",
        "    \n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split into {len(chunks)} chunks.\")\n",
        "    \n",
        "    # Create embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "    \n",
        "    # Create vector store\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    return vector_store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW958AiMCuEH"
      },
      "source": [
        "# Generate response using RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp6o4sjOCwnf"
      },
      "outputs": [],
      "source": [
        "def answer_question(question, vector_store, model):\n",
        "    \"\"\"Generate an answer using Retrieval-Augmented Generation.\"\"\"\n",
        "    # Retrieve relevant documents\n",
        "    docs = vector_store.similarity_search(question, k=5)\n",
        "    \n",
        "    # Create context from retrieved documents\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    \n",
        "    # Generate prompt for Gemini\n",
        "    prompt = f\"\"\"\n",
        "    You are a teaching assistant helping students with Computer Science and Technology for Software Engineering (CTSE) concepts.\n",
        "    Answer the following question based ONLY on the provided context from CTSE lecture notes.\n",
        "    If you cannot find the answer in the context, state that you don't have that information.\n",
        "    \n",
        "    Context:\n",
        "    {context}\n",
        "    \n",
        "    Question: {question}\n",
        "    \n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    \n",
        "    # Generate response\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdraJWatDAgb"
      },
      "source": [
        "# Main execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyqoGUBsDHzl"
      },
      "outputs": [],
      "source": [
        "print(\"=== CTSE Lecture Notes Chatbot ===\")\n",
        "\n",
        "# Setup model\n",
        "print(\"Setting up the Gemini model...\")\n",
        "model = setup_gemini(GEMINI_API_KEY)\n",
        "\n",
        "# Load documents\n",
        "print(\"\\nLoading documents from the 'datasets' folder...\")\n",
        "documents = load_documents()\n",
        "\n",
        "if not documents:\n",
        "    print(\"No documents found. Please make sure your CTSE lecture notes are in the 'datasets' folder.\")\n",
        "else:\n",
        "    # Process documents\n",
        "    print(\"\\nProcessing documents and creating vector store...\")\n",
        "    vector_store = create_vector_store(documents)\n",
        "    \n",
        "    if vector_store:\n",
        "        print(\"\\nChatbot ready! You can now ask questions about your CTSE lecture notes.\")\n",
        "        print(\"Type 'exit' to end the conversation.\")\n",
        "        \n",
        "        # Chat loop\n",
        "        while True:\n",
        "            question = input(\"\\nYour question: \")\n",
        "            \n",
        "            if question.lower() in ['exit', 'quit', 'bye']:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "            \n",
        "            # Answer the question\n",
        "            print(\"Generating answer...\")\n",
        "            answer = answer_question(question, vector_store, model)\n",
        "            display(Markdown(f\"**Answer:**\\n{answer}\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
